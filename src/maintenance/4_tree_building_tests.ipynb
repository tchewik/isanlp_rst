{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree building evaluation on gold EDUs (mostly) and playground for tree building scripts\n",
    "\n",
    "1. Modifications of library components for tree building\n",
    "2. Scripts for test and evaluation of Sklearn-, AllenNLP- and gold-annotation-based RST parsers on manually segmented corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.print_tree import printBTree\n",
    "#from utils.rst_annotation import DiscourseUnit\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isanlp.annotation_rst import DiscourseUnit\n",
    "\n",
    "class DiscourseUnitCreator:\n",
    "    def __init__(self, id):\n",
    "        self.id = id\n",
    "        \n",
    "    def __call__(self, left_node, right_node, proba):\n",
    "        self.id += 1\n",
    "        return DiscourseUnit(\n",
    "            id=id,\n",
    "            left=left_node,\n",
    "            right=right_node,\n",
    "            relation=1,\n",
    "            proba=proba\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from isanlp_rst.src.isanlp_rst.sklearn_classifier import SklearnClassifier\n",
    "#from isanlp_rst.src.isanlp_rst.allennlp_classifier import AllenNLPClassifier\n",
    "#from isanlp_rst.src.isanlp_rst.allennlp_classifier_custom_bimpm import AllenNLPClassifier as LargeAllenNLPClassifier\n",
    "from isanlp_rst.src.isanlp_rst.rst_tree_predictor import *\n",
    "from isanlp_rst.src.isanlp_rst.greedy_rst_parser import GreedyRSTParser\n",
    "from isanlp_rst.src.isanlp_rst.features_extractor import FeaturesExtractor\n",
    "#from isanlp_rst.src.isanlp_rst.features_processor_default import FeaturesProcessorTokenizer as FeaturesProcessor\n",
    "from isanlp_rst.src.isanlp_rst.features_processor_default import FeaturesProcessor\n",
    "from isanlp_rst.src.isanlp_rst.classifier_wrappers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.train_test_split import split_train_dev_test\n",
    "\n",
    "train, dev, test = split_train_dev_test('./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation (Parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_SPAN_PREDICTOR = {\n",
    "    'lstm': (AllenNLPCustomBiMPMClassifier, 'structure_predictor_lstm', 0., 0.5),\n",
    "    'baseline': (SklearnClassifier, 'structure_predictor', 0.15, 0.2),\n",
    "    'ensemble': (EnsembleClassifier,)\n",
    "}\n",
    "\n",
    "_LABEL_PREDICTOR = {\n",
    "    'lstm': (AllenNLPBiMPMClassifier, 'label_predictor_lstm'),\n",
    "    'baseline': (SklearnClassifier, 'label_predictor'),\n",
    "    'ensemble': (EnsembleClassifier,)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "neural_binary_classifier = _SPAN_PREDICTOR['lstm'][0]('models/structure_predictor_bimpm/fresh-sweep-1/')\n",
    "baseline_binary_classifier = _SPAN_PREDICTOR['baseline'][0]('models/structure_predictor_baseline/')\n",
    "binary_classifier = _SPAN_PREDICTOR['ensemble'][0]((neural_binary_classifier, baseline_binary_classifier))\n",
    "\n",
    "neural_label_classifier = _LABEL_PREDICTOR['lstm'][0]('models/label_predictor_bimpm/usual-sweep-1/')\n",
    "baseline_label_classifier = _LABEL_PREDICTOR['baseline'][0]('models/relation_predictor_baseline/')\n",
    "label_classifier = _LABEL_PREDICTOR['ensemble'][0]((neural_label_classifier, baseline_label_classifier))\n",
    "\n",
    "features_processor = FeaturesProcessor(model_dir_path='models', verbose=False)\n",
    "features_extractor = FeaturesExtractor(features_processor)\n",
    "\n",
    "_predictor = [LargeNNTreePredictor,  # both classifiers are neural\n",
    "              EnsembleNNTreePredictor,  # structure predictions are neural, for labels use an ensemble\n",
    "              DoubleEnsembleNNTreePredictor,  # both classifiers are ensembles\n",
    "             ]  \n",
    "predictor = _predictor[2](features_processor=features_extractor, \n",
    "                            relation_predictor_sentence=None,\n",
    "                            relation_predictor_text=binary_classifier, \n",
    "                            label_predictor=label_classifier)\n",
    "\n",
    "paragraph_parser = GreedyRSTParser(predictor,\n",
    "                                   confidence_threshold=_SPAN_PREDICTOR['lstm'][2])\n",
    "\n",
    "document_parser = GreedyRSTParser(predictor,\n",
    "                                  confidence_threshold=_SPAN_PREDICTOR['lstm'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_document_parser = GreedyRSTParser(predictor,\n",
    "                                             confidence_threshold=_SPAN_PREDICTOR['lstm'][3]-0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isanlp.annotation import Sentence\n",
    "\n",
    "def split_by_paragraphs(annot_text, annot_tokens, annot_sentences, annot_lemma, annot_morph, annot_postag,\n",
    "                        annot_syntax_dep_tree):\n",
    "\n",
    "    def split_on_two(sents, boundary):\n",
    "        list_sum = lambda l: sum([len(sublist) for sublist in l])\n",
    "\n",
    "        i = 1\n",
    "        while list_sum(sents[:i]) < boundary and i < len(sents):\n",
    "            i += 1\n",
    "\n",
    "        intersentence_boundary = min(len(sents[i - 1]), boundary - list_sum(sents[:i - 1]))\n",
    "        return (sents[:i - 1] + [sents[i - 1][:intersentence_boundary]],\n",
    "                [sents[i - 1][intersentence_boundary:]] + sents[i:])\n",
    "\n",
    "    def recount_sentences(chunk):\n",
    "        sentences = []\n",
    "        lemma = []\n",
    "        morph = []\n",
    "        postag = []\n",
    "        syntax_dep_tree = []\n",
    "        tokens_cursor = 0\n",
    "\n",
    "        for i, sent in enumerate(chunk['syntax_dep_tree']):\n",
    "            if len(sent) > 0:\n",
    "                sentences.append(Sentence(tokens_cursor, tokens_cursor + len(sent)))\n",
    "                lemma.append(chunk['lemma'][i])\n",
    "                morph.append(chunk['morph'][i])\n",
    "                postag.append(chunk['postag'][i])\n",
    "                syntax_dep_tree.append(chunk['syntax_dep_tree'][i])\n",
    "                tokens_cursor += len(sent)\n",
    "\n",
    "        chunk['sentences'] = sentences\n",
    "        chunk['lemma'] = lemma\n",
    "        chunk['morph'] = morph\n",
    "        chunk['postag'] = postag\n",
    "        chunk['syntax_dep_tree'] = syntax_dep_tree\n",
    "\n",
    "        return chunk\n",
    "\n",
    "    chunks = []\n",
    "    prev_right_boundary = -1\n",
    "\n",
    "    for i, token in enumerate(annot_tokens[:-1]):\n",
    "\n",
    "        if '\\n' in annot_text[token.end:annot_tokens[i + 1].begin]:\n",
    "            if prev_right_boundary > -1:\n",
    "                chunk = {\n",
    "                    'text': annot_text[annot_tokens[prev_right_boundary].end:token.end + 1].strip(),\n",
    "                    'tokens': annot_tokens[prev_right_boundary + 1:i + 1]\n",
    "                }\n",
    "            else:\n",
    "                chunk = {\n",
    "                    'text': annot_text[:token.end + 1].strip(),\n",
    "                    'tokens': annot_tokens[:i + 1]\n",
    "                }\n",
    "\n",
    "            lemma, annot_lemma = split_on_two(annot_lemma, i - prev_right_boundary)\n",
    "            morph, annot_morph = split_on_two(annot_morph, i - prev_right_boundary)\n",
    "            postag, annot_postag = split_on_two(annot_postag, i - prev_right_boundary)\n",
    "            syntax_dep_tree, annot_syntax_dep_tree = split_on_two(annot_syntax_dep_tree, i - prev_right_boundary)\n",
    "\n",
    "            chunk.update({\n",
    "                'lemma': lemma,\n",
    "                'morph': morph,\n",
    "                'postag': postag,\n",
    "                'syntax_dep_tree': syntax_dep_tree,\n",
    "            })\n",
    "            chunks.append(recount_sentences(chunk))\n",
    "\n",
    "            prev_right_boundary = i  # number of last token in the last chunk\n",
    "\n",
    "    chunk = {\n",
    "        'text': annot_text[annot_tokens[prev_right_boundary].end:].strip(),\n",
    "        'tokens': annot_tokens[prev_right_boundary + 1:],\n",
    "        'lemma': annot_lemma,\n",
    "        'morph': annot_morph,\n",
    "        'postag': annot_postag,\n",
    "        'syntax_dep_tree': annot_syntax_dep_tree,\n",
    "    }\n",
    "\n",
    "    chunks.append(recount_sentences(chunk))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_paragraphs_edus(edus, text):\n",
    "    res = []\n",
    "    parag = []\n",
    "    \n",
    "    for edu in edus:\n",
    "        parag.append(edu)\n",
    "        boundary = text.find(edu)+len(edu)\n",
    "        if boundary < len(text):\n",
    "            if text[boundary] == '\\n':\n",
    "                res.append(parag)\n",
    "                parag = []\n",
    "         \n",
    "    if parag:\n",
    "        res.append(parag)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluation import prepare_gold_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find edus containing multiple paragraphs and add to exceptions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "from utils.file_reading import *\n",
    "from utils.evaluation import extr_pairs, extr_pairs_forest\n",
    "\n",
    "\n",
    "broken_files = []\n",
    "smallest_file = 'data/news2_4.edus'\n",
    "coolest_file = 'data/blogs_17.edus'\n",
    "shit = 'data/blogs_99.edus'\n",
    "#test[:1]\n",
    "for file in tqdm(test):\n",
    "    filename = '.'.join(file.split('.')[:-1])\n",
    "    edus = read_edus(filename)\n",
    "    #gold = read_gold(filename)\n",
    "    gold = prepare_gold_pairs(read_gold(filename, features=True))\n",
    "    \n",
    "    annot = read_annotation(filename)\n",
    "    \n",
    "    for missegmentation in (\"\\nIMG\", \n",
    "                            \"\\nгимнастический коврик;\",\n",
    "                            \"\\nгантели или бутылки с песком;\",\n",
    "                            \"\\nнебольшой резиновый мяч;\",\n",
    "                            \"\\nэластичная лента (эспандер);\",\n",
    "                            \"\\nхула-хуп (обруч).\",\n",
    "                            \"\\n200?\",\n",
    "                            \"\\n300?\",\n",
    "                            \"\\nНе требуйте странного.\",\n",
    "                            \"\\nИспользуйте мою модель.\",\n",
    "                            '\\n\"А чего вы от них требуете?\"',\n",
    "                            '\\n\"Решить проблемы с тестерами\".',\n",
    "                            \"\\nКак гончая на дичь.\", \"\\nИ крупная.\",\n",
    "                            \"\\nВ прошлом году компания удивила рынок\",\n",
    "                            \"\\nЧужой этики особенно.\",\n",
    "                            \"\\nНо и своей тоже.\",\n",
    "                            \"\\nАэропорт имени,\",\n",
    "                            \"\\nА вот и монголы.\",\n",
    "                            \"\\nЗолотой Будда.\", \n",
    "                            \"\\nДворец Богдо-Хана.\",\n",
    "                            \"\\nПлощадь Сухэ-Батора.\",\n",
    "                            \"\\nОдноклассники)\",\n",
    "                            \"\\nВечерняя площадь.\",\n",
    "                            \"\\nТугрики.\",\n",
    "                            \"\\nВнутренние монголы.\",\n",
    "                            \"\\nВид сверху.\",\n",
    "                            \"\\nНациональный парк Тэрэлж. IMG IMG\",\n",
    "                            '\\nГора \"Черепаха\".',\n",
    "                            \"\\nПуть к медитации.\",\n",
    "                            \"\\nЖить надо высоко,\",\n",
    "                            \"\\nЧан с кумысом.\",\n",
    "                            \"\\nЖилая юрта.\",\n",
    "                            \"\\nКумыс.\",\n",
    "                            \"\\nТрадиционное занятие монголов\",\n",
    "                            \"\\nДвугорбый верблюд мало где\",\n",
    "                            \"\\nМонгол Шуудан переводится\",\n",
    "                            \"\\nОвощные буузы.\",\n",
    "                            \"\\nЗнаменитый чай!\"\n",
    "                            ):\n",
    "        annot['text'] = annot['text'].replace(missegmentation, ' '+missegmentation[1:])\n",
    "\n",
    "    for edu in edus:\n",
    "        if annot['text'].find(edu) == -1:\n",
    "            print(f'::: {filename} ::: {edu}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.export_to_rs3 import ForestExporter  # for list of units (whole document)\n",
    "from utils.export_to_rs3 import Exporter  # for single unit (one tree)\n",
    "\n",
    "exporter = ForestExporter(encoding='utf-8')\n",
    "\n",
    "! mkdir gold_predictions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "from utils.file_reading import *\n",
    "from utils.evaluation import *\n",
    "\n",
    "\n",
    "broken_files = []\n",
    "smallest_file = 'data/news2_4.edus'\n",
    "weirdest_file = 'data/blogs_63.edus'\n",
    "\n",
    "for file in tqdm(test):\n",
    "    filename = '.'.join(file.split('.')[:-1])\n",
    "    edus = read_edus(filename)\n",
    "    gold = prepare_gold_pairs(read_gold(filename, features=True))\n",
    "    annot = read_annotation(filename)\n",
    "    \n",
    "    for missegmentation in (\"\\nIMG\", \n",
    "                            \"\\nгимнастический коврик;\",\n",
    "                            \"\\nгантели или бутылки с песком;\",\n",
    "                            \"\\nнебольшой резиновый мяч;\",\n",
    "                            \"\\nэластичная лента (эспандер);\",\n",
    "                            \"\\nхула-хуп (обруч).\",\n",
    "                            \"\\n200?\",\n",
    "                            \"\\n300?\",\n",
    "                            \"\\nНе требуйте странного.\",\n",
    "                            \"\\nИспользуйте мою модель.\",\n",
    "                            '\\n\"А чего вы от них требуете?\"',\n",
    "                            '\\n\"Решить проблемы с тестерами\".',\n",
    "                            \"\\nКак гончая на дичь.\", \"\\nИ крупная.\",\n",
    "                            \"\\nВ прошлом году компания удивила рынок\",\n",
    "                            \"\\nЧужой этики особенно.\",\n",
    "                            \"\\nНо и своей тоже.\",\n",
    "                            \"\\nАэропорт имени,\",\n",
    "                            \"\\nА вот и монголы.\",\n",
    "                            \"\\nЗолотой Будда.\", \n",
    "                            \"\\nДворец Богдо-Хана.\",\n",
    "                            \"\\nПлощадь Сухэ-Батора.\",\n",
    "                            \"\\nОдноклассники)\",\n",
    "                            \"\\nВечерняя площадь.\",\n",
    "                            \"\\nТугрики.\",\n",
    "                            \"\\nВнутренние монголы.\",\n",
    "                            \"\\nВид сверху.\",\n",
    "                            \"\\nНациональный парк Тэрэлж. IMG IMG\",\n",
    "                            '\\nГора \"Черепаха\".',\n",
    "                            \"\\nПуть к медитации.\",\n",
    "                            \"\\nЖить надо высоко,\",\n",
    "                            \"\\nЧан с кумысом.\",\n",
    "                            \"\\nЖилая юрта.\",\n",
    "                            \"\\nКумыс.\",\n",
    "                            \"\\nТрадиционное занятие монголов\",\n",
    "                            \"\\nДвугорбый верблюд мало где\",\n",
    "                            \"\\nМонгол Шуудан переводится\",\n",
    "                            \"\\nОвощные буузы.\",\n",
    "                            \"\\nЗнаменитый чай!\",\n",
    "                            ):\n",
    "        annot['text'] = annot['text'].replace(missegmentation, ' '+missegmentation[1:])\n",
    "\n",
    "    \n",
    "    if '\\n' in annot['text']:\n",
    "        chunks = split_by_paragraphs(\n",
    "            annot['text'],\n",
    "            annot['tokens'], \n",
    "            annot['sentences'], \n",
    "            annot['lemma'], \n",
    "            annot['morph'], \n",
    "            annot['postag'], \n",
    "            annot['syntax_dep_tree'])\n",
    "        \n",
    "        chunked_edus = split_by_paragraphs_edus(edus, annot['text'])\n",
    "    \n",
    "    dus = []\n",
    "    start_id = 0\n",
    "    for i, chunk in enumerate(tqdm(chunks)):\n",
    "        _edus = []\n",
    "        last_end = 0\n",
    "        \n",
    "        for max_id in range(len(chunked_edus[i])):\n",
    "            start = len(annot['text'][:last_end]) + annot['text'][last_end:].find(chunked_edus[i][max_id])\n",
    "            end = start + len(chunked_edus[i][max_id])\n",
    "            temp = DiscourseUnit(\n",
    "                    id=start_id,\n",
    "                    left=None,\n",
    "                    right=None,\n",
    "                    relation='edu',\n",
    "                    start=start,\n",
    "                    end=end,\n",
    "                    orig_text=annot['text'],\n",
    "                    proba=1.,\n",
    "                )\n",
    "\n",
    "            _edus.append(temp)\n",
    "            last_end = end + 1\n",
    "            start_id += 1\n",
    "            \n",
    "        if len(_edus) == 1:\n",
    "            dus += _edus\n",
    "            start_id = _edus[-1].id + 1\n",
    "\n",
    "        elif len(_edus) > 1:\n",
    "            trees = paragraph_parser(_edus,\n",
    "                annot['text'], chunk['tokens'], chunk['sentences'], chunk['lemma'],\n",
    "                chunk['morph'], chunk['postag'], chunk['syntax_dep_tree'])\n",
    "            \n",
    "            dus += trees\n",
    "#             print('::: chunk processed :::')\n",
    "#             print(dus[-1].text)\n",
    "            start_id = max([tree.id for tree in dus]) + 1\n",
    "        \n",
    "    parsed = document_parser(\n",
    "                dus, \n",
    "                annot['text'], \n",
    "                annot['tokens'], \n",
    "                annot['sentences'], \n",
    "                annot['lemma'], \n",
    "                annot['morph'], \n",
    "                annot['postag'], \n",
    "                annot['syntax_dep_tree'],\n",
    "                genre=filename.split('_')[0])\n",
    "    \n",
    "    if len(parsed) > len(annot['text']) // 400:\n",
    "        parsed = additional_document_parser(\n",
    "            parsed, \n",
    "            annot['text'], \n",
    "            annot['tokens'], \n",
    "            annot['sentences'], \n",
    "            annot['lemma'], \n",
    "            annot['morph'], \n",
    "            annot['postag'], \n",
    "            annot['syntax_dep_tree'],\n",
    "            genre=filename.split('_')[0]\n",
    "        )\n",
    "        \n",
    "    exporter(parsed, f\"gold_predictions/{filename.split('/')[-1]}_parsed_goldedu.rs3\")\n",
    "    parsed_pairs = pd.DataFrame(extr_pairs_forest(parsed, annot['text']), \n",
    "                                columns=['snippet_x', 'snippet_y', 'category_id', 'order'])\n",
    "    evaluation = eval_pipeline(parsed_pairs=parsed_pairs,\n",
    "                               gold_edus=edus,\n",
    "                               gold_pairs=gold[['snippet_x', 'snippet_y', 'category_id', 'order']],\n",
    "                               text=annot['text'],\n",
    "                               trees=parsed)\n",
    "    evaluation['filename'] = file\n",
    "    print(evaluation)\n",
    "    cache.append(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parsed[0].right.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.file_reading import *\n",
    "from utils.evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(parsed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parsed[4].right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tmp = pd.DataFrame(cache[7:27] + cache[28:])\n",
    "tmp = pd.DataFrame(cache)\n",
    "tmp['pr_seg'] = tmp.seg_true_pred / tmp.seg_all_pred\n",
    "tmp['re_seg'] = tmp.seg_true_pred / tmp.seg_all_true\n",
    "tmp['f1_seg'] = 2 * tmp.pr_seg * tmp.re_seg / (tmp.pr_seg + tmp.re_seg)\n",
    "tmp['pr_unlab'] = tmp.unlab_true_pred / tmp.unlab_all_pred\n",
    "tmp['re_unlab'] = tmp.unlab_true_pred / tmp.unlab_all_true\n",
    "tmp['f1_unlab'] = 2 * tmp.pr_unlab * tmp.re_unlab / (tmp.pr_unlab + tmp.re_unlab)\n",
    "tmp['pr_lab'] = tmp.lab_true_pred / tmp.lab_all_pred\n",
    "tmp['re_lab'] = tmp.lab_true_pred / tmp.lab_all_true\n",
    "tmp['f1_lab'] = 2 * tmp.pr_lab * tmp.re_lab / (tmp.pr_lab + tmp.re_lab)\n",
    "tmp['pr_nuc'] = tmp.nuc_true_pred / tmp.nuc_all_pred\n",
    "tmp['re_nuc'] = tmp.nuc_true_pred / tmp.nuc_all_true\n",
    "tmp['f1_nuc'] = 2 * tmp.pr_nuc * tmp.re_nuc / (tmp.pr_nuc + tmp.re_nuc)\n",
    "tmp['pr_full'] = tmp.full_true_pred / tmp.full_all_pred\n",
    "tmp['re_full'] = tmp.full_true_pred / tmp.full_all_true\n",
    "tmp['f1_full'] = 2 * tmp.pr_full * tmp.re_full / (tmp.pr_full + tmp.re_full)\n",
    "tmp.sort_values('f1_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp2 = tmp[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp2[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp2[tmp2.filename.str.contains('news')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlabeled tree building score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pr_micro = tmp.unlab_true_pred.sum() / tmp.unlab_all_pred.sum() * 100.\n",
    "re_micro = tmp.unlab_true_pred.sum() / tmp.unlab_all_true.sum() * 100.\n",
    "f1_micro = 2. * pr_micro * re_micro / (pr_micro + re_micro)\n",
    "\n",
    "unlab_micro = (pr_micro, re_micro, f1_micro)\n",
    "unlab_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_macro = tmp.pr_unlab.sum() / tmp.shape[0] * 100.\n",
    "re_macro = tmp.re_unlab.sum() / tmp.shape[0] * 100.\n",
    "f1_macro = 2. * pr_macro * re_macro / (pr_macro + re_macro)\n",
    "\n",
    "unlab_macro = (pr_macro, re_macro, f1_macro)\n",
    "unlab_macro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeled tree building score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_micro = tmp.lab_true_pred.sum() / tmp.lab_all_pred.sum() * 100.\n",
    "re_micro = tmp.lab_true_pred.sum() / tmp.lab_all_true.sum() * 100.\n",
    "f1_micro = 2. * pr_micro * re_micro / (pr_micro + re_micro)\n",
    "\n",
    "lab_micro = (pr_micro, re_micro, f1_micro)\n",
    "lab_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_macro = tmp.pr_lab.sum() / tmp.shape[0] * 100.\n",
    "re_macro = tmp.re_lab.sum() / tmp.shape[0] * 100.\n",
    "f1_macro = 2. * pr_macro * re_macro / (pr_macro + re_macro)\n",
    "\n",
    "lab_macro = (pr_macro, re_macro, f1_macro)\n",
    "lab_macro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuclearity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_micro = tmp.nuc_true_pred.sum() / tmp.nuc_all_pred.sum() * 100.\n",
    "re_micro = tmp.nuc_true_pred.sum() / tmp.nuc_all_true.sum() * 100.\n",
    "f1_micro = 2. * pr_micro * re_micro / (pr_micro + re_micro)\n",
    "\n",
    "nuc_micro = (pr_micro, re_micro, f1_micro)\n",
    "nuc_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pr_macro = tmp.pr_nuc.sum() / tmp.shape[0] * 100.\n",
    "re_macro = tmp.re_nuc.sum() / tmp.shape[0] * 100.\n",
    "f1_macro = 2. * pr_macro * re_macro / (pr_macro + re_macro)\n",
    "\n",
    "nuc_macro = (pr_macro, re_macro, f1_macro)\n",
    "nuc_macro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full tree building score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_micro = tmp.full_true_pred.sum() / tmp.full_all_pred.sum() * 100.\n",
    "re_micro = tmp.full_true_pred.sum() / tmp.full_all_true.sum() * 100.\n",
    "f1_micro = 2. * pr_micro * re_micro / (pr_micro + re_micro)\n",
    "\n",
    "full_micro = pr_micro, re_micro, f1_micro\n",
    "full_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_macro = tmp.pr_full.sum() / tmp.shape[0] * 100.\n",
    "re_macro = tmp.re_full.sum() / tmp.shape[0] * 100.\n",
    "f1_macro = 2. * pr_macro * re_macro / (pr_macro + re_macro)\n",
    "\n",
    "full_macro = (pr_macro, re_macro, f1_macro)\n",
    "full_macro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_table = pd.DataFrame(columns=['component', 'P', 'R', 'F1', 'P', 'R', 'F1'], data=[\n",
    "    #['segmentation', overall_score['pr_seg'], overall_score['re_seg'], overall_score['f1_seg']],\n",
    "    ['span', unlab_micro[0], unlab_micro[1], unlab_micro[2], unlab_macro[0], unlab_macro[1], unlab_macro[2]],\n",
    "    ['nuclearity', nuc_micro[0], nuc_micro[1], nuc_micro[2], nuc_macro[0], nuc_macro[1], nuc_macro[2]],\n",
    "    ['relation', lab_micro[0], lab_micro[1], lab_micro[2], lab_macro[0], lab_macro[1], lab_macro[2]],\n",
    "    ['full', full_micro[0], full_micro[1], full_micro[2], full_macro[0], full_macro[1], full_macro[2]],\n",
    "])\n",
    "\n",
    "print(evaluation_table.to_latex(index=False, float_format='%.2f', column_format='|l|l|l|l|'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation (Gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluation import metric_parseval_df as metric_parseval\n",
    "from utils.evaluation import extr_pairs_forest\n",
    "from utils.file_reading import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "true_pos = []\n",
    "all_parsed = []\n",
    "all_gold = []\n",
    "\n",
    "for key, value in cache.items():\n",
    "    c_true_pos, c_all_parsed, c_all_gold = metric_parseval(value[0], value[1])\n",
    "    filenames.append(key)\n",
    "    true_pos.append(c_true_pos)\n",
    "    all_parsed.append(c_all_parsed)\n",
    "    all_gold.append(c_all_gold)\n",
    "    \n",
    "results = pd.DataFrame({'filename': filenames, \n",
    "                    'true_pos': true_pos,\n",
    "                    'all_parsed': all_parsed,\n",
    "                    'all_gold': all_gold})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isanlp_rst.src.isanlp_rst.rst_tree_predictor import GoldTreePredictor\n",
    "from export.to_rs3 import ForestExporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_golds(filename):\n",
    "    filename = '.'.join(filename.split('.')[:-1])\n",
    "    edus = read_edus(filename)\n",
    "    gold = read_gold(filename)\n",
    "    annot = read_annotation(filename)\n",
    "    \n",
    "    _edus = []\n",
    "    last_end = 0\n",
    "    last_id = 0\n",
    "    for max_id in range(len(edus)):\n",
    "        start = len(annot['text'][:last_end]) + annot['text'][last_end:].find(edus[max_id])\n",
    "        end = start + len(edus[max_id])\n",
    "        temp = DiscourseUnit(\n",
    "                id=max_id + last_id,\n",
    "                left=None,\n",
    "                right=None,\n",
    "                relation='edu',\n",
    "                start=start,\n",
    "                end=end,\n",
    "                orig_text=annot['text'],\n",
    "                proba=1.,\n",
    "            )\n",
    "        _edus.append(temp)\n",
    "        last_end = end\n",
    "        last_id += 1\n",
    "\n",
    "    parser = GreedyRSTParser(GoldTreePredictor(gold), confidence_threshold=0.)\n",
    "    parsed = parser(_edus, annot['text'], annot['tokens'], annot['sentences'],\n",
    "                    annot['postag'], annot['morph'], annot['lemma'], annot['syntax_dep_tree'])\n",
    "    \n",
    "    exp = ForestExporter(encoding='utf8')\n",
    "    filename = filename.split('/')[-1]\n",
    "    exp(parsed, 'parsed_golds_0406/'+filename+'.rs3')\n",
    "    \n",
    "    parsed_pairs = pd.DataFrame(extr_pairs_forest(parsed, annot['text'], locations=True), \n",
    "                                columns=['snippet_x', 'snippet_y', 'category_id', 'order', 'loc_x', 'loc_y'])\n",
    "    \n",
    "#     parsed_pairs[0] = parsed_pairs.snippet_x\n",
    "#     parsed_pairs[1] = parsed_pairs.snippet_y\n",
    "    \n",
    "    return (filename,) + metric_parseval(parsed_pairs, gold)#, parsed_pairs#, parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, parsed_pairs = parse_golds('data/news1_28.edus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parsed_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_pairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "pool = mp.Pool(5)\n",
    "result = pool.map(parse_golds, test)\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['filename', 'true_pos', 'all_parsed', 'all_gold'], data=result)\n",
    "difference = results['all_parsed'] - results['true_pos']\n",
    "results['all_gold'] += difference\n",
    "results['true_pos'] = results['all_parsed']\n",
    "\n",
    "results['recall'] = results['true_pos'] / results['all_gold']\n",
    "results['precision'] = results['true_pos'] / results['all_parsed']\n",
    "results['F1'] = 2 * results['precision'] * results['recall'] / (results['precision'] + results['recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results.sort_values('F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "read_gold('data/news1_28', features=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_pairs['filename'] = 'news1_28'\n",
    "gold_pairs = read_gold('data/news1_28', features=False)\n",
    "#gold_pairs['category_id'] = gold_pairs['category_id'].map(lambda row: row[:-2])\n",
    "res = pd.concat([parsed_pairs, gold_pairs]).drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gold_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[res.snippet_x.str.contains('Когда в окрестности Урана прибыл ')].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_json('data/news1_28.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parsed[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_pairs.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results.F1.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
