import os

from allennlp.predictors import Predictor


class AllenNLPClassifier:
    """
    Wrapper for allennlp classification model along with preprocessors, saved in the same directory:
        [required]
        - model.tar.gz            : trained model
    """

    def __init__(self, model_dir_path):
        self.model_dir_path = model_dir_path
        self._max_len = 250

        self._model = Predictor.from_path(os.path.join(self.model_dir_path, 'model.tar.gz'))

    def predict_proba(self, snippet_x, snippet_y):
        if len(snippet_x.split()) > self._max_len or len(snippet_x.split()) == 0 or len(
                snippet_y.split()) > self._max_len or len(snippet_y.split()) == 0:
            return [1., 0.]

        return self._model.predict(self._prepare_sequence(snippet_x), self._prepare_sequence(snippet_y))['probs']

    def predict_proba_batch(self, snippet_x, snippet_y):
        predictions = self._model.predict_batch_json([
            {'premise': self._prepare_sequence(snippet_x[i]),
             'hypothesis': self._prepare_sequence(snippet_y[i])} if 0 < len(snippet_x[i].split()) <= self._max_len and 0 < len(
                snippet_y[i].split()) <= self._max_len else
            {'premise': '1', 'hypothesis': '-'}
            for i in range(len(snippet_x))])

        return [prediction['probs'] for prediction in predictions]

    def predict(self, snippet_x, snippet_y):
        if len(snippet_x.split()) > self._max_len or len(snippet_x.split()) == 0 or len(
                snippet_y.split()) > self._max_len or len(snippet_y.split()) == 0:
            return [1., 0.]
        
        return self._model.predict(self._prepare_sequence(snippet_x), self._prepare_sequence(snippet_y))['label']

    def predict_batch(self, snippet_x, snippet_y):
        predictions = self._model.predict_batch_json([
            {'premise': self._prepare_sequence(snippet_x[i]),
             'hypothesis': self._prepare_sequence(snippet_y[i])} if 0 < len(snippet_x[i].split()) <= self._max_len and 0 < len(
                snippet_y[i].split()) <= self._max_len else
            {'premise': '1', 'hypothesis': '-'}
            for i in range(len(snippet_x))])
        
        return [prediction['label'] for prediction in predictions]

    def _prepare_sequence(self, sequence):
        symbol_map = {
            'x': 'Ñ…',
            'X': 'X',
            'y': 'Ñƒ',
            'â€”': '-',
            'â€œ': 'Â«',
            'â€˜': 'Â«',
            'â€': 'Â»',
            'â€™': 'Â»',
            'ðŸ˜†': 'ðŸ˜„',
            'ðŸ˜Š': 'ðŸ˜„',
            'ðŸ˜‘': 'ðŸ˜„',
            'ðŸ˜”': 'ðŸ˜„',
            'ðŸ˜‰': 'ðŸ˜„',
            'â—': 'ðŸ˜„',
            'ðŸ¤”': 'ðŸ˜„',
            'ðŸ˜…': 'ðŸ˜„',
            'âš“': 'ðŸ˜„',
            'Îµ': 'Î±',
            'Î¶': 'Î±',
            'Î·': 'Î±',
            'Î¼': 'Î±',
            'Î´': 'Î±',
            'Î»': 'Î±',
            'Î½': 'Î±',
            'Î²': 'Î±',
            'Î³': 'Î±',
            'Î½': 'Î±',
            'ã¨': 'å°‹',
            'ã®': 'å°‹',
            'ç¥ž': 'å°‹',
            'éš ': 'å°‹',
            'ã—': 'å°‹',
        }
        
        result = []
        
        for token in sequence.split():

            for key, value in symbol_map.items():
                token = token.replace(key, value)

            for keyword in ['www', 'http']:
                if keyword in token:
                    token = '_html_'
            
            result.append(token)
            
        return ' '.join(result)
    